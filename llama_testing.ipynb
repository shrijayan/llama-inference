{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from llama_model/llama-2-13b-chat.Q4_0.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q4_0:  281 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q4_0\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 6.86 GiB (4.53 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n",
      "llm_load_tensors:        CPU buffer size =  7023.90 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 7000\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  5468.75 MiB\n",
      "llama_new_context_with_model: KV self size  = 5468.75 MiB, K (f16): 2734.38 MiB, V (f16): 2734.38 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =     0.40 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =     9.17 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '2'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "\n",
    "llm = LlamaCpp(\n",
    "        model_path=\"llama_model/llama-2-13b-chat.Q4_0.gguf\", n_ctx=7000,\n",
    "        temperature=0.2,\n",
    "        max_tokens=200,\n",
    "        top_p=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mllm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[38;5;124;43m[INST] <<SYS>>\u001b[39;49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;43m    You are a helpful, respectful and honest assistant where you job is Evaluation. Always answer as helpfully as possible, while being safe. Please ensure that your responses are socially unbiased and positive in nature. If you don\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt know the answer to a question, please don\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt share false information. <</SYS>>\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;43m                \u001b[39;49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;43m                Question: What is the global incidence of lung cancer, and how does it contribute to cancer-related mortality?\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \n\u001b[1;32m      7\u001b[0m \u001b[38;5;124;43m                \u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;43m                Embedding 1:\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;43m                Answer: Clinical recommendations for perioperative immunotherapy‐induced adverse events in patients with non‐small cell lung cancer\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;43mTP‐AbCMV‐DNAEBV‐DNANovel coronavirus antibody (IgM\u001b[39;49m\u001b[38;5;130;43;01m\\u2009\u001b[39;49;00m\u001b[38;5;124;43m+\u001b[39;49m\u001b[38;5;130;43;01m\\u2009\u001b[39;49;00m\u001b[38;5;124;43mIgG)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m              \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m              \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                Autoantibodies\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43md\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mANA spectrumANCA spectrumRheumatoid associated antibodyAntibody against acetylcholinesteraseAnti‐Hu/Yo/Ri antibody (blood + cerebrospinal fluid) (for patients with small cell lung cancer)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m              \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m              \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                Skin\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mIn case of new skin lesions or aggravation of existing skin lesions, skin and mucosa (conjunctiva, oral mucosa, nasal mucosa, perianal mucosa, etc.) should be examined\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m              \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m              \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                Pancreas\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mBlood amylase and lipase\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mIf there are symptoms, consider abdominal enhanced CT (pancreatic thin scan) or MRCP\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m              \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m              \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                Thyroid gland\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43me\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mThyroid function test: Thyroid stimulating hormone (TSH), free thyroxine (fT4), free triiodothyronine (fT3)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mIf the baseline thyroid function is abnormal, check TT3 and TT4, fT3 and fT4, antiperoxidase antibody (TPO), antithyroglobulin antibody (TgAb) and thyrotropin receptor antibody (TRAb)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m              \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m              \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                Adrenal gland/pituitary gland\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43me\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mBlood cortisol (preferred in the morning, 8:00\u001b[39;49m\u001b[38;5;130;43;01m\\u2009\u001b[39;49;00m\u001b[38;5;124;43ma.m.), adrenocorticotropic hormone (ACTH) (8:00\u001b[39;49m\u001b[38;5;130;43;01m\\u2009\u001b[39;49;00m\u001b[38;5;124;43ma.m.)\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mIf the baseline examination is abnormal, improve six sex hormones (LH [luteinizing hormone], FSH [follicle stimulating hormone], T [testosterone], P [progesterone], E2 [estradiol], PRL [prolactin]) and insulin‐like growth factor (IGF‐1); Pituitary MRI\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m              \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m              \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                Lung\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m                \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43mOxygen saturation (resting and active)Routine pulmonary function test (PETs) was performed before operation,\u001b[39;49m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;43mRole of the Microbiota in Lung Cancer: Insights on Prevention and Treatment\u001b[39;49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;43mrouge” that connects these different entities, especially regarding the innate immunity sector, which plays a crucial role in the immune surveillance of cancer and in the functionality of the MIS. \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      Specifically, the mucosal-associated invariant T (MAITs) cells are a population of mucosal innate immunity T-like cells that recognizes specific bacterial metabolites presented by molecules with the MR1 antigen [46]. The acknowledgment of the potential of MAITs has rendered them extremely interesting in the development of therapies for diseases such as HIV, tuberculosis, and cancer [47]. The activated MAIT cells are highly proliferative and perform a cytolytic action mediated by granzyme B and perforin towards target cells. In addition to the antigenic recognition of a wide range of bacteria, they can also be recalled and activated by chemokines [48]. MAIT cells have been found to be particularly active in the control of intracellular infections, as seen in Mycobacteria tuberculosis lung infections [49], and this could be a very interesting aspect when related to the observation of Nejman and collaborators [45] regarding the intracellular localization of intratumoral bacteria. The role of MAIT cells in tumor immunity is still debated. In 2016, the activity of MAIT cells was linked with the development of tumors of the gastric, lung, and colon mucosa [50]. Precisely, MAITs migrated massively from the circulation to the tumor site of the colon due to chemokine recall. However, despite the antitumor potential shown in vitro in K562 cells, their peripheral circulatory deficiency and their presence in the tumor site have been correlated with progression and a worse prognosis for mucosal-associated tumors.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      Although the modeling and regulating functions of the intestinal microbiota on the host’s immune system are recognized, the communication methods and movements of immune cells between the intestine and other organs need further investigation. Starting from the study of the anatomical and functional distribution mechanisms of natural killer (NK) cells, which are fundamental in response to viral infections and in cancer immunosurveillance, distinguished into the main categories of immature/precursor and differentiated/effector, it has been observed that immature and precursor NKs were predominantly present in lymph nodes and intestines in a tissue-specific manner, functioning as organism reservoir sites [51]. The differentiation triggered the distribution via the bloodstream to the bone marrow, spleen, and lungs, where they performed immunosurveillance to exert their cytotoxic action. The same authors highlighted that the preferential distribution of effector NKs was consistent with their role in identifying infected and metastatic cells.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      A study conducted in 2014 [52] focused on transgenic mice for a photoconvertible fluorescent protein. Impressive lymphocyte traffic to and from the intestine and the proximal and distal lymph nodes was recorded, and attention was paid to the movements of Th17 cells, notoriously involved in the distal responses most influenced by the gut. The central role of the intestinal environment in the formation of immune responses has been confirmed again.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      Much attention should also be paid to B cells and tumor-infiltrating PCs, whose presence been associated with better prognosis in ovarian cancer [53]. Biswas and coworkers showed instead how the IgA-mediated humoral response regulates immunity against ovarian cancer and is associated with a better prognosis. In detail, it was found that the IgA not specific for tumor antigens, produced by the infiltrating B cells, redirected the T and B cells themselves against the tumor, causing cytolysis. In addition, thanks to the activation of internal transcriptional changes, the process of transcytosis of IgA through the tumor cells makes them sensitive to attack by T lymphocytes [54].\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      Another particularly intriguing target is represented by extracellular vesicles produced by intestinal immune and epithelial cells and by commensal bacteria. The content of the exosomes, which varies according to the environment and the type of message to be communicated, is generally referred to as a set of bioactive effectors and genetic material (e.g., microRNAs, antigens, AMP, growth factors, etc.) [55]. Such vesicles have been shown to be involved in innumerable physiological and pathological processes. In an interesting and complex study, it was observed in vitro and ex vivo that microvesicles produced by the probiotic L. rhamnosus JB-1 induced DCs towards an immunoregulatory phenotype and even influenced the peristaltic activity by acting directly on the enteric nerve [56]. Again, Zhang and coworkers showed that exosomal veins produced by gastric carcinoma cells transported and translocated the EGFR receptor in liver cell membranes, triggering the metastatic process in the liver [57]. Another key interaction of extracellular vesicles concerns NK cells, which can be activated\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;43mA Comprehensive Survey on the Progress, Process, and Challenges of Lung Cancer Detection and Classification\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;43mincreases. This makes measuring the area/volume of tiny nodules more difficult. The partial-volume approach (PVM) [396] is presented for calculating nodule volume based on the consistency of the average attenuation quantities. PVM outperforms other thresholding algorithms in volumetric accuracy, according to their phantom study. SPVA (segmentation-based partial-volume analysis) [397] is proposed to extend the PVM approach to include VOI segmentation into the nodule core, parenchyma area, and partial-volume region. A histogram from the partial volume region was used to estimate the volume of the nodule near its boundary. Finally, the proposed RAGF [398] yields an elliptical approximation of the lesion boundary.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          11.3.2. Nodules Attached to Vessels\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          Lung nodules are frequently connected to other pulmonary structures such as the airways, blood vessels, parenchymal walls, and diaphragm. Because the CT values of nodules and these non-target objects are frequently extremely similar, determining the extent of the nodule from these structures becomes a difficult technical issue. Juxta-vascular nodules are nodules that connect to blood vessels. Morphological filtering is a systematic strategy for this purpose [397, 399–403]. Because the proportion of nodules that attach to vessels/airways is often minimal compared to the entire extent of the 3D nodule surface, basic MOs such as erosion, dilatation, and opening are frequently effective in most juxta-vascular situations [400, 402]. These fundamental operators were combined with convex-hull operations [397, 404] and 3D moment analysis [405] to refine the segmentation process after it was completed. Geometric/shape constrained segmentation is another prominent strategy in this context [398, 403, 406–408]. This method incorporates shape-based prior information into the segmentation process to bias the results toward a spherical/nodular shape. It suppresses elongated non-target components linked to the target.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          11.3.3. Nodules Attached to Parenchymal Wall and Diaphragm\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          Juxta-pleural nodules are cases that are attached to the parenchymal wall or the diaphragm. These nodules are connected to the chest wall and pleural surface. Many automated measurement algorithms struggle with these nodules because they need to determine where the nodule ends and the chest wall begins. Solitary nodules, on the other hand, that do not border any other structures, such as airways or blood arteries, are much easier to segment [409].\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          11.3.4. Ground-Glass Opacity Nodules\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          The ground-glass opacity (GGO) nodule is a nodule with subsolid CT values that are much lower than usual solid nodules. They are classified into two types based on whether or not solid components are present: non-solid/pure and partially solid/mixed. GGO nodule segmentation is a technological issue because it is difficult to distinguish their tiny boundaries and model their uneven appearances. In clinical practice, modern CT technology\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms more excellent picture resolution has enabled the investigation of small GGO nodules. Although their growth is frequently slow [410], such GGO nodules, particularly mixed ones, have been linked to a high risk of malignancy [411]. Recent clinical studies are part of the histological spectrum of peripheral adenocarcinomas, which encompass premalignant atypical adenomatous hyperplasia (AAH) and malignant bronchioloalveolar carcinoma (BAC) [412]. Over ten years, a tiny non-solid GGO representing AAH or BAC can gradually grow into an invasive lung adenocarcinoma [410]. In this method, segmentation is accomplished by labeling each voxel with a nodule/background label based on a probabilistic decision rule established from training data.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        11.4. Article Selection Bias\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        A measurement of association, such as a risk ratio, that is distorted as a result of sample selection that does not accurately reflect the target population is known as selection bias. The selection of individuals, groups, or\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \n\u001b[1;32m     22\u001b[0m \u001b[38;5;124;43m                \u001b[39;49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124;43m                Embedding 2:\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;124;43m                Answer: Global burden and trends of lung cancer incidence and mortality\u001b[39;49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;43mContent: [\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      Introduction\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      Lung cancer is the most commonly diagnosed cancer and the leading cause of cancer-related deaths globally. According to GLOBOCAN 2020, an estimated 2.2 million new lung cancer cases (11.4\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m) and almost 1.8 million lung cancer deaths (18.0\u001b[39;49m\u001b[38;5;124;43m%\u001b[39;49m\u001b[38;5;124;43m) occurred in 2020.[1] The burden of lung cancer varies among different countries mainly because of divergent risk factors, such as the prevalence of smoking, environmental pollution, and even dietary habits.[2] In the United States of America (USA), the incidence of lung cancer has gradually declined since 1990,[3] due to the effective tobacco control policies and regulations. However, some developing countries, including China, exhibit a lower incidence but higher mortality from lung cancer. The reason for such patterns includes incomplete early cancer screening, poor medical conditions, and challenges with tobacco control policies and regulations.[4]\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      Therefore, this study aimed to describe and compare country-specific morbidity and mortality of lung cancer rates in 2020, and analyze the incidence trend in major countries.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      Methods\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        Data sources\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        The incidence and mortality of lung cancer were derived from the GLOBOCAN 2020 database (https://gco.iarc.fr/).[5] It is a web-based interactive platform that provides the International Agency for Research on Cancer (IARC) global cancer statistics for 36 cancer types in 185 countries or territories, supplying information for cancer control and research.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        To analyze the temporal trends of lung cancer incidence, we extracted cancer incidence data from the Cancer in Five Continents Time Trends (CI5plus) database,[6] which contains high-quality population-based cancer registries, including continuous incidence data from 108 countries or territories or subnational population-based cancer registries.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        The Human Development Index (HDI) is a comprehensive index based on the three basic variables of “education level, life expectancy and quality of life” according to the following formula[7,8]: HDI\u001b[39;49m\u001b[38;5;130;43;01m\\u200a\u001b[39;49;00m\u001b[38;5;124;43m=\u001b[39;49m\u001b[38;5;130;43;01m\\u200a\u001b[39;49;00m\u001b[38;5;124;43m(IEducation × IHealth × IIncome)1/3. Based on the principle of the Human Development Statistic of the United Nations Development Programme,[9] countries were categorized into four levels according to HDI values (very high HDI, ≥0.800; high HDI, 0.700–0.799; medium HDI, 0.550–0.699; and low HDI, <0.550).\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        In this study, the International Classification of Diseases 10th revision data code C33–34 was derived from the overall cancer database to analyze the lung cancer incidence and mortality rates.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        Selected countries\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        The 20 countries with the highest ASIRs of lung cancer defined by the United Nations Population Division were selected to assess lung cancer incidence and mortality in 2020. A representative sample of five countries (China, South Korea, the USA, the United Kingdom, and Australia) on four continents were selected and they had complete and continuous data for analyzing the incidence trends from 2000 to 2012.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        Statistical analysis\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        The ASIR and ASMR were calculated from Segi\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms world standard population.[10] Lung cancer incidence and mortality in 2020 were grouped by country, sex, and age. We used Joinpoint regression (version 4.3.1.0, National Cancer Institute, USA) to analyze temporal trends in lung cancer incidence and mortality for five continents and calculated the average annual percent change (AAPC). The Z test was used to examine whether the average annual percent change has shown upward or downward trends and was statistically different from zero. The association of lung cancer ASIR and ASMR with HDI was detected by linear regression. P values <0.05 were considered statistically significant.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m    \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      Results\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        Lung cancer incidence and mortality rates in 2020\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        An estimated 2.2 million new lung cancer cases and 1.8 million lung cancer-related deaths occurred in 2020, accounting for approximately 11.4\u001b[39;49m\u001b[38;5;132;43;01m% o\u001b[39;49;00m\u001b[38;5;124;43mf the\u001b[39;49m\n\u001b[1;32m     27\u001b[0m \n\u001b[1;32m     28\u001b[0m \u001b[38;5;124;43mMapping of global, regional and national incidence, mortality and mortality-to-incidence ratio of lung cancer in 2020 and 2050\u001b[39;49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;43mAbstract: [\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          Aim\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          Lung cancer is the leading cause of cancer deaths worldwide. This study examines the current and future burden of lung cancer at global, regional, and national levels.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          Methods\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          The estimates of lung cancer incident cases, deaths, and their age-standardized rates are drawn from GLOBOCAN 2020 for 21 regions and 185 countries. Mortality-to-incidence ratio (MIR) is considered as a proxy indicator of 5-year survival rates. Lung cancer burden in 2050 is projected using age-specific incidence and death rates in 2020.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          Results\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          In 2020, there were 2.21 million new cases and 1.8 million deaths due to lung cancer worldwide with age-standardized incidence rate (ASIR) of 22.4/100,000 (male: 31.5; female: 14.6) and age-standardized mortality rates (ASMR) of 18.0/100,000, (male: 25.9; female: 11.2/100,000). Global MIR of lung cancer was 0.82 (males 0.83; females: 0.79), varying from 0.59 (Japan) to 1.0 (Belize). Hungary had the highest age-standardized rates (ASIR: 50.1/100,000; ASMR: 42.4/100,000) and Nigeria (ASIR: 0.88; ASMR: 0.86) had the lowest age-standardized rates\u001b[39;49m\u001b[38;5;130;43;01m\\xa0\u001b[39;49;00m\u001b[38;5;124;43min 2020. Both ASIR and ASMR were positively correlated with country-level tobacco smoking prevalence and human development index (HDI), whereas MIR exhibited\u001b[39;49m\u001b[38;5;130;43;01m\\xa0\u001b[39;49;00m\u001b[38;5;124;43ma negative correlation with HDI. As per our projections, there will be 3.8 million incident cases and 3.2 million deaths\u001b[39;49m\u001b[38;5;130;43;01m\\xa0\u001b[39;49;00m\u001b[38;5;124;43mglobally due to lung cancer in 2050.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          Conclusion\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          With close to 2 million cases and deaths already in 2020, lung cancer has already become\u001b[39;49m\u001b[38;5;130;43;01m\\xa0\u001b[39;49;00m\u001b[38;5;124;43ma global public health threat. Even with current risk levels and age-specific\u001b[39;49m\u001b[38;5;130;43;01m\\xa0\u001b[39;49;00m\u001b[38;5;124;43mrates, lung cancer annual cases are expected to reach 3.8 million in 2050. Until smoking prevalence is reduced and ambient air pollution levels are checked, particularly in low/medium HDI countries, the lung cancer epidemic will continue unfolding.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          Supplementary Information\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          The online version contains supplementary material available at 10.1007/s10147-021-02108-2.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;43mGlobal burden and trends of lung cancer incidence and mortality\u001b[39;49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;43mAbstract: [\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        Abstract\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          Background:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          Lung cancer has been the leading cause of cancer-related deaths worldwide for many years. This study aimed to investigate the global patterns and trends of lung cancer.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          Methods:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          Lung cancer incidence and mortality were derived from the GLOBOCAN 2020 database. Continuous data from Cancer Incidence in Five Continents Time Trends were used to analyze the temporal trends from 2000 to 2012 using Joinpoint regression, and average annual percent changes were calculated. The association between the Human Development Index and lung cancer incidence and mortality was assessed by linear regression.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          Results:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          An estimated 2.2 million new lung cancer cases and 1.8 million lung cancer-related deaths occurred in 2020. The age-standardized incidence rate (ASIR) ranged from 36.8 per 100,000 in Demark to 5.9 per 100,000 in Mexico. The age-standardized mortality rate (ASMR) varied from 32.8 per 100,000 in Poland to 4.9 per 100,000 in Mexico. Both ASIR and ASMR were approximately twice higher in men than in women. The ASIR of lung cancer showed a downward trend in the United States of America (USA) between 2000 and 2012, and was more prominent in men. The age-specific incidence rates of lung cancer for ages of 50 to 59 years showed an upward trend in China for both men and women.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          Conclusions:\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m          The burden of lung cancer is still unsatisfactory, especially in developing countries like China. Considering the effectiveness of tobacco control and screening in developed countries, such as the USA, there is a need to strengthen health education, accelerate the establishment of tobacco control policies and regulations, and improve early cancer screening awareness to reduce the future burden of lung cancer.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m        \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m      \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;43m                \u001b[39;49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;43m                Compare both the Embeddings and calculate which output is more related to the question and give output as score from 0 to 1. Produce only the Output score no need of explanation or any other text. Still if you are not able to calculate the answer return the score as 0[/INST]\u001b[39;49m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;43m                \u001b[39;49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124;43m                Output:\u001b[39;49m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;43m                Embedding 1: [your_calculated_score]\u001b[39;49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;43m                Embedding 2: [your_calculated_score] \u001b[39;49m\u001b[38;5;124;43m'''\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/embedding/embedding_venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:145\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     emit_warning()\n\u001b[0;32m--> 145\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/embedding/embedding_venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:991\u001b[0m, in \u001b[0;36mBaseLLM.__call__\u001b[0;34m(self, prompt, stop, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(prompt, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    985\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `prompt` is expected to be a string. Instead found \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(prompt)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If you want to run the LLM on multiple prompts, use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`generate` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    989\u001b[0m     )\n\u001b[1;32m    990\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 991\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    992\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    993\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1000\u001b[0m     \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m   1001\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/embedding/embedding_venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:741\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    726\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to cache, but no cache found at `langchain.cache`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    727\u001b[0m         )\n\u001b[1;32m    728\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    729\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    730\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    739\u001b[0m         )\n\u001b[1;32m    740\u001b[0m     ]\n\u001b[0;32m--> 741\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Projects/embedding/embedding_venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:605\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    604\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 605\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    606\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
      "File \u001b[0;32m~/Projects/embedding/embedding_venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:592\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    583\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    584\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 592\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    599\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    600\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    601\u001b[0m         )\n\u001b[1;32m    602\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    603\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/Projects/embedding/embedding_venv/lib/python3.10/site-packages/langchain_core/language_models/llms.py:1177\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1174\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1176\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1177\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1180\u001b[0m     )\n\u001b[1;32m   1181\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
      "File \u001b[0;32m~/Projects/embedding/embedding_venv/lib/python3.10/site-packages/langchain_community/llms/llamacpp.py:288\u001b[0m, in \u001b[0;36mLlamaCpp._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstreaming:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;66;03m# If streaming is enabled, we use the stream\u001b[39;00m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;66;03m# method that yields as they are generated\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;66;03m# and return the combined strings from the first choices's text:\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     combined_text_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream(\n\u001b[1;32m    289\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m    290\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    291\u001b[0m         run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m    292\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    293\u001b[0m     ):\n\u001b[1;32m    294\u001b[0m         combined_text_output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m combined_text_output\n",
      "File \u001b[0;32m~/Projects/embedding/embedding_venv/lib/python3.10/site-packages/langchain_community/llms/llamacpp.py:341\u001b[0m, in \u001b[0;36mLlamaCpp._stream\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_parameters(stop), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[1;32m    340\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient(prompt\u001b[38;5;241m=\u001b[39mprompt, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 341\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m part \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m    342\u001b[0m     logprobs \u001b[38;5;241m=\u001b[39m part[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    343\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m GenerationChunk(\n\u001b[1;32m    344\u001b[0m         text\u001b[38;5;241m=\u001b[39mpart[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    345\u001b[0m         generation_info\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogprobs\u001b[39m\u001b[38;5;124m\"\u001b[39m: logprobs},\n\u001b[1;32m    346\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/embedding/embedding_venv/lib/python3.10/site-packages/llama_cpp/llama.py:978\u001b[0m, in \u001b[0;36mLlama._create_completion\u001b[0;34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[0m\n\u001b[1;32m    976\u001b[0m finish_reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlength\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    977\u001b[0m multibyte_fix \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 978\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[1;32m    979\u001b[0m     prompt_tokens,\n\u001b[1;32m    980\u001b[0m     top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    981\u001b[0m     top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[1;32m    982\u001b[0m     min_p\u001b[38;5;241m=\u001b[39mmin_p,\n\u001b[1;32m    983\u001b[0m     typical_p\u001b[38;5;241m=\u001b[39mtypical_p,\n\u001b[1;32m    984\u001b[0m     temp\u001b[38;5;241m=\u001b[39mtemperature,\n\u001b[1;32m    985\u001b[0m     tfs_z\u001b[38;5;241m=\u001b[39mtfs_z,\n\u001b[1;32m    986\u001b[0m     mirostat_mode\u001b[38;5;241m=\u001b[39mmirostat_mode,\n\u001b[1;32m    987\u001b[0m     mirostat_tau\u001b[38;5;241m=\u001b[39mmirostat_tau,\n\u001b[1;32m    988\u001b[0m     mirostat_eta\u001b[38;5;241m=\u001b[39mmirostat_eta,\n\u001b[1;32m    989\u001b[0m     frequency_penalty\u001b[38;5;241m=\u001b[39mfrequency_penalty,\n\u001b[1;32m    990\u001b[0m     presence_penalty\u001b[38;5;241m=\u001b[39mpresence_penalty,\n\u001b[1;32m    991\u001b[0m     repeat_penalty\u001b[38;5;241m=\u001b[39mrepeat_penalty,\n\u001b[1;32m    992\u001b[0m     stopping_criteria\u001b[38;5;241m=\u001b[39mstopping_criteria,\n\u001b[1;32m    993\u001b[0m     logits_processor\u001b[38;5;241m=\u001b[39mlogits_processor,\n\u001b[1;32m    994\u001b[0m     grammar\u001b[38;5;241m=\u001b[39mgrammar,\n\u001b[1;32m    995\u001b[0m ):\n\u001b[1;32m    996\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_token_eos:\n\u001b[1;32m    997\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdetokenize(completion_tokens)\n",
      "File \u001b[0;32m~/Projects/embedding/embedding_venv/lib/python3.10/site-packages/llama_cpp/llama.py:663\u001b[0m, in \u001b[0;36mLlama.generate\u001b[0;34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 663\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_tokens:\n\u001b[1;32m    665\u001b[0m         token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msample(\n\u001b[1;32m    666\u001b[0m             top_k\u001b[38;5;241m=\u001b[39mtop_k,\n\u001b[1;32m    667\u001b[0m             top_p\u001b[38;5;241m=\u001b[39mtop_p,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    681\u001b[0m             idx\u001b[38;5;241m=\u001b[39msample_idx,\n\u001b[1;32m    682\u001b[0m         )\n",
      "File \u001b[0;32m~/Projects/embedding/embedding_venv/lib/python3.10/site-packages/llama_cpp/llama.py:503\u001b[0m, in \u001b[0;36mLlama.eval\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    499\u001b[0m n_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch\u001b[38;5;241m.\u001b[39mset_batch(\n\u001b[1;32m    501\u001b[0m     batch\u001b[38;5;241m=\u001b[39mbatch, n_past\u001b[38;5;241m=\u001b[39mn_past, logits_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_params\u001b[38;5;241m.\u001b[39mlogits_all\n\u001b[1;32m    502\u001b[0m )\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_ids[n_past : n_past \u001b[38;5;241m+\u001b[39m n_tokens] \u001b[38;5;241m=\u001b[39m batch\n",
      "File \u001b[0;32m~/Projects/embedding/embedding_venv/lib/python3.10/site-packages/llama_cpp/_internals.py:305\u001b[0m, in \u001b[0;36m_LlamaContext.decode\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m return_code \u001b[38;5;241m=\u001b[39m \u001b[43mllama_cpp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/embedding/embedding_venv/lib/python3.10/site-packages/llama_cpp/llama_cpp.py:1636\u001b[0m, in \u001b[0;36mllama_decode\u001b[0;34m(ctx, batch)\u001b[0m\n\u001b[1;32m   1631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mllama_decode\u001b[39m(ctx: llama_context_p, batch: llama_batch) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m   1632\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Positive return values does not mean a fatal error, but rather a warning.\u001b[39;00m\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;124;03m    0 - success\u001b[39;00m\n\u001b[1;32m   1634\u001b[0m \u001b[38;5;124;03m    1 - could not find a KV slot for the batch (try reducing the size of the batch or increase the context)\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;124;03m    < 0 - error\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1636\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "llm('''You are a helpful, respectful and honest assistant where you job is Evaluation. Always answer as helpfully as possible, while being safe. Please ensure that your responses are socially unbiased and positive in nature. If you don't know the answer to a question, please don't share false information.\n",
    "                \n",
    "                Question: What is the global incidence of lung cancer, and how does it contribute to cancer-related mortality?\n",
    "\n",
    "\n",
    "                \n",
    "                Embedding 1:\n",
    "\n",
    "                Answer: Clinical recommendations for perioperative immunotherapy‐induced adverse events in patients with non‐small cell lung cancer\n",
    "TP‐AbCMV‐DNAEBV‐DNANovel coronavirus antibody (IgM\\u2009+\\u2009IgG)\\n\\n                \\n                \\n              \\n              \\n                Autoantibodies\\nd\\n\\n\\n                \\nANA spectrumANCA spectrumRheumatoid associated antibodyAntibody against acetylcholinesteraseAnti‐Hu/Yo/Ri antibody (blood + cerebrospinal fluid) (for patients with small cell lung cancer)\\n\\n                \\n                \\n              \\n              \\n                Skin\\n                \\nIn case of new skin lesions or aggravation of existing skin lesions, skin and mucosa (conjunctiva, oral mucosa, nasal mucosa, perianal mucosa, etc.) should be examined\\n\\n                \\n                \\n              \\n              \\n                Pancreas\\n                \\nBlood amylase and lipase\\n\\n                \\nIf there are symptoms, consider abdominal enhanced CT (pancreatic thin scan) or MRCP\\n\\n                \\n              \\n              \\n                Thyroid gland\\ne\\n\\n\\n                \\nThyroid function test: Thyroid stimulating hormone (TSH), free thyroxine (fT4), free triiodothyronine (fT3)\\n\\n                \\nIf the baseline thyroid function is abnormal, check TT3 and TT4, fT3 and fT4, antiperoxidase antibody (TPO), antithyroglobulin antibody (TgAb) and thyrotropin receptor antibody (TRAb)\\n\\n                \\n              \\n              \\n                Adrenal gland/pituitary gland\\ne\\n\\n\\n                \\nBlood cortisol (preferred in the morning, 8:00\\u2009a.m.), adrenocorticotropic hormone (ACTH) (8:00\\u2009a.m.)\\n\\n                \\nIf the baseline examination is abnormal, improve six sex hormones (LH [luteinizing hormone], FSH [follicle stimulating hormone], T [testosterone], P [progesterone], E2 [estradiol], PRL [prolactin]) and insulin‐like growth factor (IGF‐1); Pituitary MRI\\n\\n                \\n              \\n              \\n                Lung\\n                \\nOxygen saturation (resting and active)Routine pulmonary function test (PETs) was performed before operation,\n",
    "\n",
    "Role of the Microbiota in Lung Cancer: Insights on Prevention and Treatment\n",
    "rouge” that connects these different entities, especially regarding the innate immunity sector, which plays a crucial role in the immune surveillance of cancer and in the functionality of the MIS. \\n      Specifically, the mucosal-associated invariant T (MAITs) cells are a population of mucosal innate immunity T-like cells that recognizes specific bacterial metabolites presented by molecules with the MR1 antigen [46]. The acknowledgment of the potential of MAITs has rendered them extremely interesting in the development of therapies for diseases such as HIV, tuberculosis, and cancer [47]. The activated MAIT cells are highly proliferative and perform a cytolytic action mediated by granzyme B and perforin towards target cells. In addition to the antigenic recognition of a wide range of bacteria, they can also be recalled and activated by chemokines [48]. MAIT cells have been found to be particularly active in the control of intracellular infections, as seen in Mycobacteria tuberculosis lung infections [49], and this could be a very interesting aspect when related to the observation of Nejman and collaborators [45] regarding the intracellular localization of intratumoral bacteria. The role of MAIT cells in tumor immunity is still debated. In 2016, the activity of MAIT cells was linked with the development of tumors of the gastric, lung, and colon mucosa [50]. Precisely, MAITs migrated massively from the circulation to the tumor site of the colon due to chemokine recall. However, despite the antitumor potential shown in vitro in K562 cells, their peripheral circulatory deficiency and their presence in the tumor site have been correlated with progression and a worse prognosis for mucosal-associated tumors.\\n      Although the modeling and regulating functions of the intestinal microbiota on the host’s immune system are recognized, the communication methods and movements of immune cells between the intestine and other organs need further investigation. Starting from the study of the anatomical and functional distribution mechanisms of natural killer (NK) cells, which are fundamental in response to viral infections and in cancer immunosurveillance, distinguished into the main categories of immature/precursor and differentiated/effector, it has been observed that immature and precursor NKs were predominantly present in lymph nodes and intestines in a tissue-specific manner, functioning as organism reservoir sites [51]. The differentiation triggered the distribution via the bloodstream to the bone marrow, spleen, and lungs, where they performed immunosurveillance to exert their cytotoxic action. The same authors highlighted that the preferential distribution of effector NKs was consistent with their role in identifying infected and metastatic cells.\\n      A study conducted in 2014 [52] focused on transgenic mice for a photoconvertible fluorescent protein. Impressive lymphocyte traffic to and from the intestine and the proximal and distal lymph nodes was recorded, and attention was paid to the movements of Th17 cells, notoriously involved in the distal responses most influenced by the gut. The central role of the intestinal environment in the formation of immune responses has been confirmed again.\\n      Much attention should also be paid to B cells and tumor-infiltrating PCs, whose presence been associated with better prognosis in ovarian cancer [53]. Biswas and coworkers showed instead how the IgA-mediated humoral response regulates immunity against ovarian cancer and is associated with a better prognosis. In detail, it was found that the IgA not specific for tumor antigens, produced by the infiltrating B cells, redirected the T and B cells themselves against the tumor, causing cytolysis. In addition, thanks to the activation of internal transcriptional changes, the process of transcytosis of IgA through the tumor cells makes them sensitive to attack by T lymphocytes [54].\\n      Another particularly intriguing target is represented by extracellular vesicles produced by intestinal immune and epithelial cells and by commensal bacteria. The content of the exosomes, which varies according to the environment and the type of message to be communicated, is generally referred to as a set of bioactive effectors and genetic material (e.g., microRNAs, antigens, AMP, growth factors, etc.) [55]. Such vesicles have been shown to be involved in innumerable physiological and pathological processes. In an interesting and complex study, it was observed in vitro and ex vivo that microvesicles produced by the probiotic L. rhamnosus JB-1 induced DCs towards an immunoregulatory phenotype and even influenced the peristaltic activity by acting directly on the enteric nerve [56]. Again, Zhang and coworkers showed that exosomal veins produced by gastric carcinoma cells transported and translocated the EGFR receptor in liver cell membranes, triggering the metastatic process in the liver [57]. Another key interaction of extracellular vesicles concerns NK cells, which can be activated\n",
    "\n",
    "A Comprehensive Survey on the Progress, Process, and Challenges of Lung Cancer Detection and Classification\n",
    "increases. This makes measuring the area/volume of tiny nodules more difficult. The partial-volume approach (PVM) [396] is presented for calculating nodule volume based on the consistency of the average attenuation quantities. PVM outperforms other thresholding algorithms in volumetric accuracy, according to their phantom study. SPVA (segmentation-based partial-volume analysis) [397] is proposed to extend the PVM approach to include VOI segmentation into the nodule core, parenchyma area, and partial-volume region. A histogram from the partial volume region was used to estimate the volume of the nodule near its boundary. Finally, the proposed RAGF [398] yields an elliptical approximation of the lesion boundary.\\n        \\n        \\n          11.3.2. Nodules Attached to Vessels\\n          Lung nodules are frequently connected to other pulmonary structures such as the airways, blood vessels, parenchymal walls, and diaphragm. Because the CT values of nodules and these non-target objects are frequently extremely similar, determining the extent of the nodule from these structures becomes a difficult technical issue. Juxta-vascular nodules are nodules that connect to blood vessels. Morphological filtering is a systematic strategy for this purpose [397, 399–403]. Because the proportion of nodules that attach to vessels/airways is often minimal compared to the entire extent of the 3D nodule surface, basic MOs such as erosion, dilatation, and opening are frequently effective in most juxta-vascular situations [400, 402]. These fundamental operators were combined with convex-hull operations [397, 404] and 3D moment analysis [405] to refine the segmentation process after it was completed. Geometric/shape constrained segmentation is another prominent strategy in this context [398, 403, 406–408]. This method incorporates shape-based prior information into the segmentation process to bias the results toward a spherical/nodular shape. It suppresses elongated non-target components linked to the target.\\n        \\n        \\n          11.3.3. Nodules Attached to Parenchymal Wall and Diaphragm\\n          Juxta-pleural nodules are cases that are attached to the parenchymal wall or the diaphragm. These nodules are connected to the chest wall and pleural surface. Many automated measurement algorithms struggle with these nodules because they need to determine where the nodule ends and the chest wall begins. Solitary nodules, on the other hand, that do not border any other structures, such as airways or blood arteries, are much easier to segment [409].\\n        \\n        \\n          11.3.4. Ground-Glass Opacity Nodules\\n          The ground-glass opacity (GGO) nodule is a nodule with subsolid CT values that are much lower than usual solid nodules. They are classified into two types based on whether or not solid components are present: non-solid/pure and partially solid/mixed. GGO nodule segmentation is a technological issue because it is difficult to distinguish their tiny boundaries and model their uneven appearances. In clinical practice, modern CT technology's more excellent picture resolution has enabled the investigation of small GGO nodules. Although their growth is frequently slow [410], such GGO nodules, particularly mixed ones, have been linked to a high risk of malignancy [411]. Recent clinical studies are part of the histological spectrum of peripheral adenocarcinomas, which encompass premalignant atypical adenomatous hyperplasia (AAH) and malignant bronchioloalveolar carcinoma (BAC) [412]. Over ten years, a tiny non-solid GGO representing AAH or BAC can gradually grow into an invasive lung adenocarcinoma [410]. In this method, segmentation is accomplished by labeling each voxel with a nodule/background label based on a probabilistic decision rule established from training data.\\n        \\n      \\n      \\n        11.4. Article Selection Bias\\n        A measurement of association, such as a risk ratio, that is distorted as a result of sample selection that does not accurately reflect the target population is known as selection bias. The selection of individuals, groups, or\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "                Embedding 2:\n",
    "\n",
    "                Answer: Global burden and trends of lung cancer incidence and mortality\n",
    "Content: [\"\\n    \\n      Introduction\\n      Lung cancer is the most commonly diagnosed cancer and the leading cause of cancer-related deaths globally. According to GLOBOCAN 2020, an estimated 2.2 million new lung cancer cases (11.4%) and almost 1.8 million lung cancer deaths (18.0%) occurred in 2020.[1] The burden of lung cancer varies among different countries mainly because of divergent risk factors, such as the prevalence of smoking, environmental pollution, and even dietary habits.[2] In the United States of America (USA), the incidence of lung cancer has gradually declined since 1990,[3] due to the effective tobacco control policies and regulations. However, some developing countries, including China, exhibit a lower incidence but higher mortality from lung cancer. The reason for such patterns includes incomplete early cancer screening, poor medical conditions, and challenges with tobacco control policies and regulations.[4]\\n      Therefore, this study aimed to describe and compare country-specific morbidity and mortality of lung cancer rates in 2020, and analyze the incidence trend in major countries.\\n    \\n    \\n      Methods\\n      \\n        Data sources\\n        The incidence and mortality of lung cancer were derived from the GLOBOCAN 2020 database (https://gco.iarc.fr/).[5] It is a web-based interactive platform that provides the International Agency for Research on Cancer (IARC) global cancer statistics for 36 cancer types in 185 countries or territories, supplying information for cancer control and research.\\n        To analyze the temporal trends of lung cancer incidence, we extracted cancer incidence data from the Cancer in Five Continents Time Trends (CI5plus) database,[6] which contains high-quality population-based cancer registries, including continuous incidence data from 108 countries or territories or subnational population-based cancer registries.\\n        The Human Development Index (HDI) is a comprehensive index based on the three basic variables of “education level, life expectancy and quality of life” according to the following formula[7,8]: HDI\\u200a=\\u200a(IEducation × IHealth × IIncome)1/3. Based on the principle of the Human Development Statistic of the United Nations Development Programme,[9] countries were categorized into four levels according to HDI values (very high HDI, ≥0.800; high HDI, 0.700–0.799; medium HDI, 0.550–0.699; and low HDI, <0.550).\\n        In this study, the International Classification of Diseases 10th revision data code C33–34 was derived from the overall cancer database to analyze the lung cancer incidence and mortality rates.\\n      \\n      \\n        Selected countries\\n        The 20 countries with the highest ASIRs of lung cancer defined by the United Nations Population Division were selected to assess lung cancer incidence and mortality in 2020. A representative sample of five countries (China, South Korea, the USA, the United Kingdom, and Australia) on four continents were selected and they had complete and continuous data for analyzing the incidence trends from 2000 to 2012.\\n      \\n      \\n        Statistical analysis\\n        The ASIR and ASMR were calculated from Segi's world standard population.[10] Lung cancer incidence and mortality in 2020 were grouped by country, sex, and age. We used Joinpoint regression (version 4.3.1.0, National Cancer Institute, USA) to analyze temporal trends in lung cancer incidence and mortality for five continents and calculated the average annual percent change (AAPC). The Z test was used to examine whether the average annual percent change has shown upward or downward trends and was statistically different from zero. The association of lung cancer ASIR and ASMR with HDI was detected by linear regression. P values <0.05 were considered statistically significant.\\n      \\n    \\n    \\n      Results\\n      \\n        Lung cancer incidence and mortality rates in 2020\\n        An estimated 2.2 million new lung cancer cases and 1.8 million lung cancer-related deaths occurred in 2020, accounting for approximately 11.4% of the\n",
    "\n",
    "Mapping of global, regional and national incidence, mortality and mortality-to-incidence ratio of lung cancer in 2020 and 2050\n",
    "Abstract: ['\\n        \\n          Aim\\n          Lung cancer is the leading cause of cancer deaths worldwide. This study examines the current and future burden of lung cancer at global, regional, and national levels.\\n        \\n        \\n          Methods\\n          The estimates of lung cancer incident cases, deaths, and their age-standardized rates are drawn from GLOBOCAN 2020 for 21 regions and 185 countries. Mortality-to-incidence ratio (MIR) is considered as a proxy indicator of 5-year survival rates. Lung cancer burden in 2050 is projected using age-specific incidence and death rates in 2020.\\n        \\n        \\n          Results\\n          In 2020, there were 2.21 million new cases and 1.8 million deaths due to lung cancer worldwide with age-standardized incidence rate (ASIR) of 22.4/100,000 (male: 31.5; female: 14.6) and age-standardized mortality rates (ASMR) of 18.0/100,000, (male: 25.9; female: 11.2/100,000). Global MIR of lung cancer was 0.82 (males 0.83; females: 0.79), varying from 0.59 (Japan) to 1.0 (Belize). Hungary had the highest age-standardized rates (ASIR: 50.1/100,000; ASMR: 42.4/100,000) and Nigeria (ASIR: 0.88; ASMR: 0.86) had the lowest age-standardized rates\\xa0in 2020. Both ASIR and ASMR were positively correlated with country-level tobacco smoking prevalence and human development index (HDI), whereas MIR exhibited\\xa0a negative correlation with HDI. As per our projections, there will be 3.8 million incident cases and 3.2 million deaths\\xa0globally due to lung cancer in 2050.\\n        \\n        \\n          Conclusion\\n          With close to 2 million cases and deaths already in 2020, lung cancer has already become\\xa0a global public health threat. Even with current risk levels and age-specific\\xa0rates, lung cancer annual cases are expected to reach 3.8 million in 2050. Until smoking prevalence is reduced and ambient air pollution levels are checked, particularly in low/medium HDI countries, the lung cancer epidemic will continue unfolding.\\n        \\n        \\n          Supplementary Information\\n          The online version contains supplementary material available at 10.1007/s10147-021-02108-2.\\n        \\n      ']\n",
    "\n",
    "Global burden and trends of lung cancer incidence and mortality\n",
    "Abstract: ['\\n        Abstract\\n        \\n          Background:\\n          Lung cancer has been the leading cause of cancer-related deaths worldwide for many years. This study aimed to investigate the global patterns and trends of lung cancer.\\n        \\n        \\n          Methods:\\n          Lung cancer incidence and mortality were derived from the GLOBOCAN 2020 database. Continuous data from Cancer Incidence in Five Continents Time Trends were used to analyze the temporal trends from 2000 to 2012 using Joinpoint regression, and average annual percent changes were calculated. The association between the Human Development Index and lung cancer incidence and mortality was assessed by linear regression.\\n        \\n        \\n          Results:\\n          An estimated 2.2 million new lung cancer cases and 1.8 million lung cancer-related deaths occurred in 2020. The age-standardized incidence rate (ASIR) ranged from 36.8 per 100,000 in Demark to 5.9 per 100,000 in Mexico. The age-standardized mortality rate (ASMR) varied from 32.8 per 100,000 in Poland to 4.9 per 100,000 in Mexico. Both ASIR and ASMR were approximately twice higher in men than in women. The ASIR of lung cancer showed a downward trend in the United States of America (USA) between 2000 and 2012, and was more prominent in men. The age-specific incidence rates of lung cancer for ages of 50 to 59 years showed an upward trend in China for both men and women.\\n        \\n        \\n          Conclusions:\\n          The burden of lung cancer is still unsatisfactory, especially in developing countries like China. Considering the effectiveness of tobacco control and screening in developed countries, such as the USA, there is a need to strengthen health education, accelerate the establishment of tobacco control policies and regulations, and improve early cancer screening awareness to reduce the future burden of lung cancer.\\n        \\n      ']\n",
    "                \n",
    "                Compare both the Embeddings and calculate which output is more related to the question and give output as score from 0 to 1. Produce only the Output score no need of explanation or any other text. Still if you are not able to calculate the answer return the score as 0\n",
    "                \n",
    "                Output:\n",
    "                Embedding 1: [your_calculated_score]\n",
    "                Embedding 2: [your_calculated_score] ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import LlamaCpp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's work this out in a step by step way to be sure we have the right answer.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Callbacks support token-wise streaming\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 363 tensors from llama_model/llama-2-13b-chat.Q4_0.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 5120\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 40\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 13824\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 40\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 40\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 2\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   81 tensors\n",
      "llama_model_loader: - type q4_0:  281 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 5120\n",
      "llm_load_print_meta: n_head           = 40\n",
      "llm_load_print_meta: n_head_kv        = 40\n",
      "llm_load_print_meta: n_layer          = 40\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 5120\n",
      "llm_load_print_meta: n_embd_v_gqa     = 5120\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 13824\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 13B\n",
      "llm_load_print_meta: model ftype      = Q4_0\n",
      "llm_load_print_meta: model params     = 13.02 B\n",
      "llm_load_print_meta: model size       = 6.86 GiB (4.53 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.14 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llm_load_tensors:        CPU buffer size =  7023.90 MiB\n",
      "...................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 7000\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =  5468.75 MiB\n",
      "llama_new_context_with_model: KV self size  = 5468.75 MiB, K (f16): 2734.38 MiB, V (f16): 2734.38 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    24.70 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =   586.88 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 1 | AVX_VNNI = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'general.architecture': 'llama', 'llama.context_length': '4096', 'general.name': 'LLaMA v2', 'llama.embedding_length': '5120', 'llama.feed_forward_length': '13824', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.dimension_count': '128', 'llama.attention.head_count': '40', 'tokenizer.ggml.bos_token_id': '1', 'llama.block_count': '40', 'llama.attention.head_count_kv': '40', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'llama', 'general.file_type': '2'}\n"
     ]
    }
   ],
   "source": [
    "n_gpu_layers = -1  # The number of layers to put on the GPU. The rest will be on the CPU. If you don't know how many layers there are, you can use -1 to move all to GPU.\n",
    "n_batch = 512  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.\n",
    "\n",
    "# Make sure the model path is correct for your system!\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"llama_model/llama-2-13b-chat.Q4_0.gguf\",\n",
    "    n_ctx = 7000,\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True,  # Verbose is required to pass to the callback manager\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Firstly, we will calculate the similarity between both embeddings using Cosine Similarity and then compare the scores.\n",
      "\n",
      "Here's the calculation for Embedding 1:\n",
      "\n",
      "Cosine Similarity = dot(U, V) / (|U| * |V|)\n",
      "\n",
      "Where U and V are the embeddings of the two inputs, and |U| and |V| represent the magnitudes or lengths of the vectors.\n",
      "\n",
      "Using the formula, we get:\n",
      "\n",
      "Cosine Similarity = dot(U, V) / (|U| * |V|)\n",
      "\n",
      "U = [0.6783, 0.2548, 0.3215]\n",
      "V = [0.7416, 0.2954, 0.3632]\n",
      "\n",
      "dot(U, V) = 0.6783 * 0.7416 + 0.2548 * 0.2954 + 0.3215 * 0.3632\n",
      "\n",
      "= 0.5163 + 0."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   30462.27 ms\n",
      "llama_print_timings:      sample time =      38.56 ms /   256 runs   (    0.15 ms per token,  6638.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =   38107.57 ms /   636 tokens (   59.92 ms per token,    16.69 tokens per second)\n",
      "llama_print_timings:        eval time =   52539.29 ms /   255 runs   (  206.04 ms per token,     4.85 tokens per second)\n",
      "llama_print_timings:       total time =   91152.06 ms /   891 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'You are a helpful, respectful and honest assistant where you job is Evaluation. Always answer as helpfully as possible, while being safe. Please ensure that your responses are socially unbiased and positive in nature. If you don\\'t know the answer to a question, please don\\'t share false information.\\n                \\n                Question: What is the global incidence of lung cancer, and how does it contribute to cancer-related mortality?\\n\\n\\n                \\n                Embedding 1:\\n                Answer: Role of the Microbiota in Lung Cancer: Insights on Prevention and Treatment\\nrouge” that connects these different entities, especially regarding the innate immunity sector, which plays a crucial role in the immune surveillance of cancer and in the functionality of the MIS. \\n      Specifically, the mucosal-associated invariant T (MAITs) cells are a population of mucosal innate immunity T-like cells that recognizes specific bacterial metabolites presented by molecules with the MR1 antigen [46]. The acknowledgment of the potential of MAITs has rendered them extremely interesting in the development of therapies for diseases such as HIV, tuberculosis, and cancer [47].\\n\\n\\n                Embedding 2:\\n                Answer: Global burden and trends of lung cancer incidence and mortality\\nContent: [\"\\n    \\n      Introduction\\n      Lung cancer is the most commonly diagnosed cancer and the leading cause of cancer-related deaths globally. According to GLOBOCAN 2020, an estimated 2.2 million new lung cancer cases (11.4%) and almost 1.8 million lung cancer deaths (18.0%) occurred in 2020.[1] The burden of lung cancer varies among different countries mainly because of divergent risk factors, such as the prevalence of smoking, environmental pollution, and even dietary habits.[2] In the United States of America (USA), the incidence of lung cancer has gradually declined since 1990,[3] due to the effective tobacco control policies and regulations. However, some developing countries, including China, exhibit a lower incidence but higher mortality from lung cancer.\\n                \\n                Compare both the Embeddings and calculate which output is more related to the question and give output as score from 0 to 1. Produce only the Output score no need of explanation or any other text. Still if you are not able to calculate the answer return the score as 0\\n                \\n                Output:\\n                Embedding 1: [your_calculated_score]\\n                Embedding 2: [your_calculated_score] ',\n",
       " 'text': \"\\n\\nFirstly, we will calculate the similarity between both embeddings using Cosine Similarity and then compare the scores.\\n\\nHere's the calculation for Embedding 1:\\n\\nCosine Similarity = dot(U, V) / (|U| * |V|)\\n\\nWhere U and V are the embeddings of the two inputs, and |U| and |V| represent the magnitudes or lengths of the vectors.\\n\\nUsing the formula, we get:\\n\\nCosine Similarity = dot(U, V) / (|U| * |V|)\\n\\nU = [0.6783, 0.2548, 0.3215]\\nV = [0.7416, 0.2954, 0.3632]\\n\\ndot(U, V) = 0.6783 * 0.7416 + 0.2548 * 0.2954 + 0.3215 * 0.3632\\n\\n= 0.5163 + 0.\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "question = '''You are a helpful, respectful and honest assistant where you job is Evaluation. Always answer as helpfully as possible, while being safe. Please ensure that your responses are socially unbiased and positive in nature. If you don't know the answer to a question, please don't share false information.\n",
    "                \n",
    "                Question: What is the global incidence of lung cancer, and how does it contribute to cancer-related mortality?\n",
    "\n",
    "\n",
    "                \n",
    "                Embedding 1:\n",
    "                Answer: Role of the Microbiota in Lung Cancer: Insights on Prevention and Treatment\n",
    "rouge” that connects these different entities, especially regarding the innate immunity sector, which plays a crucial role in the immune surveillance of cancer and in the functionality of the MIS. \\n      Specifically, the mucosal-associated invariant T (MAITs) cells are a population of mucosal innate immunity T-like cells that recognizes specific bacterial metabolites presented by molecules with the MR1 antigen [46]. The acknowledgment of the potential of MAITs has rendered them extremely interesting in the development of therapies for diseases such as HIV, tuberculosis, and cancer [47].\n",
    "\n",
    "\n",
    "                Embedding 2:\n",
    "                Answer: Global burden and trends of lung cancer incidence and mortality\n",
    "Content: [\"\\n    \\n      Introduction\\n      Lung cancer is the most commonly diagnosed cancer and the leading cause of cancer-related deaths globally. According to GLOBOCAN 2020, an estimated 2.2 million new lung cancer cases (11.4%) and almost 1.8 million lung cancer deaths (18.0%) occurred in 2020.[1] The burden of lung cancer varies among different countries mainly because of divergent risk factors, such as the prevalence of smoking, environmental pollution, and even dietary habits.[2] In the United States of America (USA), the incidence of lung cancer has gradually declined since 1990,[3] due to the effective tobacco control policies and regulations. However, some developing countries, including China, exhibit a lower incidence but higher mortality from lung cancer.\n",
    "                \n",
    "                Compare both the Embeddings and calculate which output is more related to the question and give output as score from 0 to 1. Produce only the Output score no need of explanation or any other text. Still if you are not able to calculate the answer return the score as 0\n",
    "                \n",
    "                Output:\n",
    "                Embedding 1: [your_calculated_score]\n",
    "                Embedding 2: [your_calculated_score] '''\n",
    "llm_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embedding_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
